---
post_url: https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/280
---
usage’: {‘prompt\_tokens’: 1384,  
‘completion\_tokens’: 67,  
‘total\_tokens’: 1451,  
‘prompt\_tokens\_details’: {‘cached\_tokens’: 0, ‘audio\_tokens’: 0},  
‘completion\_tokens\_details’: {‘reasoning\_tokens’: 0, ‘audio\_tokens’: 0, ‘accepted\_prediction\_tokens’: 0, ‘rejected\_prediction\_tokens’: 0}},  
‘service\_tier’: ‘default’, ‘system\_fingerprint’: ‘fp\_13eed4fce1’,  
‘monthlyCost’: 0.5243745800000005,  
‘cost’: 0.004554000000000001

GPT-4o mini  
Fine-tuning price  
Input:--------------------------> CALCUATION: (1384/10^6)\*$0.30 = 0.0004152  
$0.30 / 1M tokens  
Cached input:  
$0.15 / 1M tokens  
Output:-------------------------> CALCUATION: (67/10^6)$1.20 = 0.0000804  
$1.20 / 1M tokens  
Training:  
$3.00 / 1M tokens  
TOTAL = 0.0004152 + 0.0000804 = 0.0004956  
‘cost’: 0.004554000000000001 MAKE IT MAKE SENSE?  
‘total\_tokens’: 1451, so only input and completion tokens used?  
  
  
  
  
  
  
  
  
INFO: Uvicorn running on <http://0.0.0.0:8000> (Press CTRL+C to quit)  
INFO:root:10  
INFO:root:Inside run\_task with task:  
Install `uv` (if required) and run the script `https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py`  
with `23f1002382@ds.study.iitm.ac.in` as the only argument

INFO:root:PRINTING RESPONSE:::PRINTING RESPONSE:::PRINTING RESPONSE:::  
{‘id’: ‘chatcmpl-B0pChhrBiCN8x8ueL2u57rwQiucl7’, ‘object’: ‘chat.completion’, ‘created’: 1739536527, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: None, ‘tool\_calls’: [{‘id’: ‘call\_ULCgfFzpEcnGNditwVwGwRIS’, ‘type’: ‘function’, ‘function’: {‘name’: ‘install\_and\_run\_script’, ‘arguments’: ‘{“package”:“uv”,“args”:[“23f1002382@ds.study.iitm.ac.in”],“script\_url”:“<https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py>”}’}}], ‘refusal’: None}, ‘logprobs’: None, ‘finish\_reason’: ‘tool\_calls’}], ‘usage’: {‘prompt\_tokens’: 1384, ‘completion\_tokens’: 67, ‘total\_tokens’: 1451, ‘prompt\_tokens\_details’: {‘cached\_tokens’: 0, ‘audio\_tokens’: 0}, ‘completion\_tokens\_details’: {‘reasoning\_tokens’: 0, ‘audio\_tokens’: 0, ‘accepted\_prediction\_tokens’: 0, ‘rejected\_prediction\_tokens’: 0}}, ‘service\_tier’: ‘default’, ‘system\_fingerprint’: ‘fp\_13eed4fce1’, ‘monthlyCost’: 0.5243745800000005, ‘cost’: 0.004554000000000001, ‘monthlyRequests’: 217}

[@s.anand](/u/s.anand) How is the usage calculated? Just asking not implying  
UPDATE: ITS EVEN MORE CHEAPER, I gave benefir of doubt better its much cheaper? ???  

```markdown
# Pricing Information for GPT Models

## GPT-4o
- **Description:** High-intelligence model for complex tasks | 128k context length
- **Price:**
  - **Input:** $2.50 / 1M tokens
  - **Cached Input:** $1.25 / 1M tokens
  - **Output:** $10.00 / 1M tokens

---

## GPT-4o mini
- **Description:** Affordable small model for fast, everyday tasks | 128k context length
- **Price:**
  - **Input:** $0.150 / 1M tokens
  - **Cached Input:** $0.075 / 1M tokens
  - **Output:** $0.600 / 1M tokens
```