---
post_url: https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/19
reply_to_post_number: 16
---
Project 1 deliverables are all that matter. How you accomplish them is not very relevant. The keys to a successful Project 1 are:  
Deliverables,  
and *an example* of the Evaluation has been provided.  
If your project runs in accordance with the Evaluation methodology then it is considered.  

```markdown
# Image Description

The image contains a document outlining specific deliverables and evaluation criteria for a project. 

## Deliverables Section:
- **Create a new GitHub repository**
- **Add an MIT LICENSE file**
- **Write and test code**: 
  - Call `POST /run?task=...` and check if `GET /read?path=...` creates the correct files.
- **Commit and push your code**
- **Create a Dockerfile** that builds your application
- **Publish your Docker image publicly to Docker Hub**
- Instructions for running the image using `podman`
- A note mentioning how to submit the work via a Google Form, including links to the GitHub repository and Docker image.

## Evaluation Section:
- Instructions regarding the use of environment variables and keeping prompts short and concise.

### Note:
- Recommendations for using the AI Proxy token and guidelines for script execution time limits.
```

Please read the documentation carefully from top to bottom.

So the main question is how do you test if the script will run according to the evaluation? The whole point is for it to run not just on your system. It should be deployable anywhere on any machine. Your solution should work anywhere we test it. Thats why you package it in a docker container. How you achieve that is up to you. But if we cannot run your docker container according to the specification we have provided then it has failed this crucial test.

Kind regards