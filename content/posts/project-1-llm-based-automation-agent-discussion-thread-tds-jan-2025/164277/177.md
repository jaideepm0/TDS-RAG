---
post_url: /t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277/177
---
<Response [200]>  
{â€˜idâ€™: â€˜chatcmpl-B0De8V66WZAucAweJe6e32BWSLnpTâ€™, â€˜objectâ€™: â€˜chat.completionâ€™, â€˜createdâ€™: 1739392156, â€˜modelâ€™: â€˜gpt-4o-mini-2024-07-18â€™, â€˜choicesâ€™: [{â€˜indexâ€™: 0, â€˜messageâ€™: {â€˜roleâ€™: â€˜assistantâ€™, â€˜contentâ€™: â€œIâ€™m sorry, but I canâ€™t assist with that.â€, â€˜refusalâ€™: None}, â€˜logprobsâ€™: None, â€˜finish\_reasonâ€™: â€˜stopâ€™}], â€˜usageâ€™: {â€˜prompt\_tokensâ€™: 874, â€˜completion\_tokensâ€™: 11, â€˜total\_tokensâ€™: 885, â€˜prompt\_tokens\_detailsâ€™: {â€˜cached\_tokensâ€™: 0, â€˜audio\_tokensâ€™: 0}, â€˜completion\_tokens\_detailsâ€™: {â€˜reasoning\_tokensâ€™: 0, â€˜audio\_tokensâ€™: 0, â€˜accepted\_prediction\_tokensâ€™: 0, â€˜rejected\_prediction\_tokensâ€™: 0}}, â€˜service\_tierâ€™: â€˜defaultâ€™, â€˜system\_fingerprintâ€™: â€˜fp\_bd83329f63â€™, â€˜monthlyCostâ€™: 0.048128640000000014, â€˜costâ€™: 0.0026880000000000003, â€˜monthlyRequestsâ€™: 51}

```
def query_gpt_image(image_path: str, task: str):
    print("ğŸ” Image Path:", image_path)
    image_format = image_path.split(".")[-1]
    with open(image_path, "rb") as file:
        image_data = base64.b64encode(file.read()).decode("utf-8")
    response = requests.post(
        "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {"APIKEY"}",
                "Content-Type": "application/json"},
        json={
            "model": "gpt-4o-mini",
            "messages": [
                {
                "role": "user",
                "content": [
                    {"type": "text", "text": task},
                    {
                    "type": "image_url",
                    "image_url": { "url": f"data:image/{image_format};base64,{image_data}" }
                    }
                ]
                }
            ]
            }
                     )
    response.raise_for_status()
    print(response)
    print(response.json())
    result = response.json() 
response = query_gpt_image("data/credit_card.png","Extract the credit card number from image")

```

Why is this not working?  
EDIT: Requires prompt engineering as â€œcredit cardâ€ is sensitive information ![:roll_eyes:](https://emoji.discourse-cdn.com/google/roll_eyes.png?v=12 ":roll_eyes:")![:roll_eyes:](https://emoji.discourse-cdn.com/google/roll_eyes.png?v=12 ":roll_eyes:")

<Response [200]>  
{â€˜idâ€™: â€˜chatcmpl-B0Dlie1ZIS68PZBCT0XJKhLKbyPACâ€™, â€˜objectâ€™: â€˜chat.completionâ€™, â€˜createdâ€™: 1739392626, â€˜modelâ€™: â€˜gpt-4o-mini-2024-07-18â€™, â€˜choicesâ€™: [{â€˜indexâ€™: 0, â€˜messageâ€™: {â€˜roleâ€™: â€˜assistantâ€™, â€˜contentâ€™: â€˜The numbers extracted from the image are:\n\n- 3009 1429 5211 59\n- 09/29\n- 113â€™, â€˜refusalâ€™: None}, â€˜logprobsâ€™: None, â€˜finish\_reasonâ€™: â€˜stopâ€™}], â€˜usageâ€™: {â€˜prompt\_tokensâ€™: 871, â€˜completion\_tokensâ€™: 31, â€˜total\_tokensâ€™: 902, â€˜prompt\_tokens\_detailsâ€™: {â€˜cached\_tokensâ€™: 0, â€˜audio\_tokensâ€™: 0}, â€˜completion\_tokens\_detailsâ€™: {â€˜reasoning\_tokensâ€™: 0, â€˜audio\_tokensâ€™: 0, â€˜accepted\_prediction\_tokensâ€™: 0, â€˜rejected\_prediction\_tokensâ€™: 0}}, â€˜service\_tierâ€™: â€˜defaultâ€™, â€˜system\_fingerprintâ€™: â€˜fp\_bd83329f63â€™, â€˜monthlyCostâ€™: 0.05092764000000002, â€˜costâ€™: 0.002799, â€˜monthlyRequestsâ€™: 52}

```
response = query_gpt_image("data/credit_card.png","Extract number from image")

```